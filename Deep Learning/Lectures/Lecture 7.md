last class we talked about activation functions, their gradients and how we cant learn XOR problem without non linearity

## Jacobians
matrix of multi variate partial derivatives


$$
\begin{align}
\frac{\partial f \circ g}{\partial x} = \frac{\partial f}{\partial g}\frac{\partial g}{\partial x}
\end{align}
$$

- chain rule will help in computation


---
## Backpropagation
---

Scipy - gradient check