[Deploying Quantization Aware Trained models in INT8 using Torch-TensorRT â€” Torch-TensorRT v1.3.0 documentation (pytorch.org)](https://pytorch.org/TensorRT/_notebooks/vgg-qat.html)
