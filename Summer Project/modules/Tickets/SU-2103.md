references 
LOE - https://github.com/torc-robotics/lidar_lane_offset_estimator/tree/development

LSGP - https://github.com/torc-robotics/localization_model_training


- is this is a blocker that new model training cannot proceed? 
- what is the protocol to merge dev variant to master? 
	- AC for moving to localization model training

account for offline training 


for training, 
- aeva data for training from scratch 
- multilane is not really required since the model is cropping
- when given access to other folders is it improving the performance of the LOE network 



- [x]  VDI setup 
- [x]  custom installations 
- [x] download aeva data 
- [x] download requiments for running (sagemaker) 
- [x] developing
- [x] tensorboard integration
	- [x] validation 
- [x] histogram 
	- [ ] histogram clipping
- [ ] aeva + old data
- [ ] bag file and check 
- [ ] how are they using in localization (in action with code)


how is it finding the submodules 
	oh it is softlinked to localization folder 

- [ ] why is it called guidecam? 
- [ ] validation analysis 
	- [ ] imagesbad vs imagesgood
	- [ ] histogram
	- [ ] diff values
	- [ ] activation map

- [ ] what all does sagemaker dump in output_bucket
- [ ] how to make it use the local cached container
- [ ] can I name the sagemaker output with timestamp?
- [ ] when does it use model and when does it use output? 

- [x] add validation set in train script
	- [x] add corresponding tensorboard logs
	- [ ] this should work with sagemaker scripts 
- [ ] pack all the outputs and models well 
- [ ] accordingly need to change the test script
- [ ] check if I can get the validation loss below 10cm
- [ ] test it with aeva + old data
- [ ] modify the dataloader for dynamically loading the images 
- [ ] create a split + val dataset from train set
- [ ] know train+ val+ test split


---
next steps
- [ ] serialize_model.py
	- [ ] naming convention of the model 
		- [ ] `Offset_LL_RL_LO_RO_120_29_LIG301.pt`
		- [ ] meaning of the naming convention
		- [ ] 
- [ ] train index right and left (right_dominant == True IndexRight)
- [ ] https://github.com/torc-robotics/lidar_lane_offset_estimator/tree/development
- [ ] run the test on th1 recorded bag file (compare against map localizer) and get consensus metrics

----
- [x] list of topics
- [x] https://github.com/torc-robotics/deployment_gen2.3/blob/main/versions.yaml

---
- [x] images of predictions
- [ ] gradients
---
- [x] install ros core
- [x] localization rviz. plugins


---
topics of interest
```
/tf
/tf_static
/global_location
/lidar_image_generator/lidar_intensity_birds_eye_view_image_tangent_frame
/lidar_image_generator/lidar_height_birds_eye_view_image_tangent_frame
/lidar_image_generator/lidar_intensity_birds_eye_view_image_vehicle_frame
/semantic_map_localizer/center_filtered_lane_offset
/semantic_map_localizer/center_filtered_lane_offset_confidence
/semantic_map_localizer/lane_index_left
/semantic_map_localizer/lane_index_right
```

nodes of interest 
```
{
    "log_pipeline": "yes",
    "components": {
        "localhost": [
            "cascadia_description",
            "health_monitor",
            "healthviz",
            "rosbridge",
            "map_broadcaster",
            "semantic_map_database",
            "lidar_lane_offset_estimator",
            "map_localizer"
        ]
    }
}
```


---
---

- [ ] why deep learning for this? 
- [ ] why cant classical method do the job? 
- [ ] is it measuring lane offset from left adjacent lane or right adjacent lane?